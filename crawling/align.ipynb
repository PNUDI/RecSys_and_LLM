{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-08 13:15:52.624494: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 13:15:52.637919: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741439752.653187 1064036 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741439752.657567 1064036 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 13:15:52.675764: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, XLNetModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000005</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Three men hammer on an anvil and pass a bottle...</td>\n",
       "      <td>Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000004</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Lost 1892 French short animated film directed ...</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Lost short film consisting of 300 painted imag...</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000003</td>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Performing on what looks like a small wooden s...</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>390752</td>\n",
       "      <td>tt0407808</td>\n",
       "      <td>Frog and Toad Are Friends</td>\n",
       "      <td>Claymation version of Arnold Lobel's story of ...</td>\n",
       "      <td>Animation,Comedy,Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>390753</td>\n",
       "      <td>tt0407810</td>\n",
       "      <td>From Ardoyne to the Áras: Inside the McAleese ...</td>\n",
       "      <td>Documentary on the private and public life of ...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>390754</td>\n",
       "      <td>tt0407811</td>\n",
       "      <td>Frontstadt</td>\n",
       "      <td>A young filmmaker tries to gain a very persona...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>390755</td>\n",
       "      <td>tt0407815</td>\n",
       "      <td>Possible Changes</td>\n",
       "      <td>Two friends, Moon-ho and Jong-kyu, in their mi...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>390756</td>\n",
       "      <td>tt0407814</td>\n",
       "      <td>Full Grown Men</td>\n",
       "      <td>A man stuck in the reveries of his youth track...</td>\n",
       "      <td>Comedy,Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         id  \\\n",
       "0                0  tt0000005   \n",
       "1                1  tt0000004   \n",
       "2                2  tt0000002   \n",
       "3                3  tt0000003   \n",
       "4                4  tt0000001   \n",
       "...            ...        ...   \n",
       "207356      390752  tt0407808   \n",
       "207357      390753  tt0407810   \n",
       "207358      390754  tt0407811   \n",
       "207359      390755  tt0407815   \n",
       "207360      390756  tt0407814   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                        Blacksmith Scene   \n",
       "1                                             Un bon bock   \n",
       "2                                  Le clown et ses chiens   \n",
       "3                                            Poor Pierrot   \n",
       "4                                              Carmencita   \n",
       "...                                                   ...   \n",
       "207356                          Frog and Toad Are Friends   \n",
       "207357  From Ardoyne to the Áras: Inside the McAleese ...   \n",
       "207358                                         Frontstadt   \n",
       "207359                                   Possible Changes   \n",
       "207360                                     Full Grown Men   \n",
       "\n",
       "                                                     desc  \\\n",
       "0       Three men hammer on an anvil and pass a bottle...   \n",
       "1       Lost 1892 French short animated film directed ...   \n",
       "2       Lost short film consisting of 300 painted imag...   \n",
       "3       One night, Arlequin come to see his lover Colo...   \n",
       "4       Performing on what looks like a small wooden s...   \n",
       "...                                                   ...   \n",
       "207356  Claymation version of Arnold Lobel's story of ...   \n",
       "207357  Documentary on the private and public life of ...   \n",
       "207358  A young filmmaker tries to gain a very persona...   \n",
       "207359  Two friends, Moon-ho and Jong-kyu, in their mi...   \n",
       "207360  A man stuck in the reveries of his youth track...   \n",
       "\n",
       "                           genre  \n",
       "0                          Short  \n",
       "1                Animation,Short  \n",
       "2                Animation,Short  \n",
       "3       Animation,Comedy,Romance  \n",
       "4              Documentary,Short  \n",
       "...                          ...  \n",
       "207356   Animation,Comedy,Family  \n",
       "207357               Documentary  \n",
       "207358                     Drama  \n",
       "207359                     Drama  \n",
       "207360              Comedy,Drama  \n",
       "\n",
       "[207361 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('cleaned_imdb_genre.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primaryTitle과 description을 하나의 텍스트로 합치기\n",
    "df['text'] = df['title'].astype(str) + \" \" + df['desc'].astype(str)\n",
    "\n",
    "# genre 컬럼 전처리: 쉼표로 구분된 문자열을 리스트로 변환\n",
    "def process_genres(genres_str):\n",
    "    if pd.isna(genres_str):\n",
    "        return []\n",
    "    return [g.strip() for g in genres_str.split(',') if g.strip() != \"\"]\n",
    "\n",
    "df['genre_list'] = df['genre'].apply(process_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 장르: ['Action', 'Adult', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'Game-Show', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']\n"
     ]
    }
   ],
   "source": [
    "all_genres = set()\n",
    "for genres in df['genre_list']:\n",
    "    for genre in genres:\n",
    "        all_genres.add(genre)\n",
    "all_genres = sorted(list(all_genres))\n",
    "genre2id = {genre: idx for idx, genre in enumerate(all_genres)}\n",
    "num_labels = len(all_genres)\n",
    "print(\"전체 장르:\", all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 샘플에 대해 멀티핫 인코딩된 레이블 생성\n",
    "def encode_labels(genres):\n",
    "    label = [0] * num_labels\n",
    "    for g in genres:\n",
    "        if g in genre2id:\n",
    "            label[genre2id[g]] = 1\n",
    "    return label\n",
    "\n",
    "df['labels'] = df['genre_list'].apply(encode_labels)\n",
    "\n",
    "# 모델 학습에 필요한 열만 선택\n",
    "df_model = df[['text', 'genre_list', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blacksmith Scene Three men hammer on an anvil ...</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un bon bock Lost 1892 French short animated fi...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le clown et ses chiens Lost short film consist...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor Pierrot One night, Arlequin come to see h...</td>\n",
       "      <td>[Animation, Comedy, Romance]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carmencita Performing on what looks like a sma...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>Frog and Toad Are Friends Claymation version o...</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>From Ardoyne to the Áras: Inside the McAleese ...</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>Frontstadt A young filmmaker tries to gain a v...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>Possible Changes Two friends, Moon-ho and Jong...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>Full Grown Men A man stuck in the reveries of ...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       Blacksmith Scene Three men hammer on an anvil ...   \n",
       "1       Un bon bock Lost 1892 French short animated fi...   \n",
       "2       Le clown et ses chiens Lost short film consist...   \n",
       "3       Poor Pierrot One night, Arlequin come to see h...   \n",
       "4       Carmencita Performing on what looks like a sma...   \n",
       "...                                                   ...   \n",
       "207356  Frog and Toad Are Friends Claymation version o...   \n",
       "207357  From Ardoyne to the Áras: Inside the McAleese ...   \n",
       "207358  Frontstadt A young filmmaker tries to gain a v...   \n",
       "207359  Possible Changes Two friends, Moon-ho and Jong...   \n",
       "207360  Full Grown Men A man stuck in the reveries of ...   \n",
       "\n",
       "                          genre_list  \\\n",
       "0                            [Short]   \n",
       "1                 [Animation, Short]   \n",
       "2                 [Animation, Short]   \n",
       "3       [Animation, Comedy, Romance]   \n",
       "4               [Documentary, Short]   \n",
       "...                              ...   \n",
       "207356   [Animation, Comedy, Family]   \n",
       "207357                 [Documentary]   \n",
       "207358                       [Drama]   \n",
       "207359                       [Drama]   \n",
       "207360               [Comedy, Drama]   \n",
       "\n",
       "                                                   labels  \n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "207356  [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "207357  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "207358  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "207359  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "207360  [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[207361 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_descriptions = {\n",
    "    \"Action\": \"This movie has thrilling action sequences with intense fight scenes.\",\n",
    "    \"Adult\": \"This film is intended for mature audiences, featuring explicit themes.\",\n",
    "    \"Adventure\": \"This movie takes the audience on an exciting journey full of discovery.\",\n",
    "    \"Animation\": \"This film is beautifully animated with vibrant characters and stunning visuals.\",\n",
    "    \"Biography\": \"This movie tells the true story of a remarkable person's life.\",\n",
    "    \"Comedy\": \"This movie is full of humor and laughter, guaranteed to entertain.\",\n",
    "    \"Crime\": \"This film revolves around criminal activities, investigations, and justice.\",\n",
    "    \"Documentary\": \"This is a factual film that explores real-life events and issues.\",\n",
    "    \"Drama\": \"This movie tells an emotional and heartfelt story with deep character development.\",\n",
    "    \"Family\": \"This movie is suitable for all ages, bringing warmth and joy to families.\",\n",
    "    \"Fantasy\": \"This film takes place in a magical world with fantastical elements and creatures.\",\n",
    "    \"Film-Noir\": \"This movie features a dark and mysterious atmosphere with complex characters.\",\n",
    "    \"Game-Show\": \"This show features competitive games and exciting challenges.\",\n",
    "    \"History\": \"This film brings historical events and figures to life with great detail.\",\n",
    "    \"Horror\": \"This movie contains scary and suspenseful moments that will keep you on edge.\",\n",
    "    \"Music\": \"This film revolves around music, featuring incredible performances and soundtracks.\",\n",
    "    \"Musical\": \"This movie is filled with songs and dance performances that tell a story.\",\n",
    "    \"Mystery\": \"This film keeps the audience guessing with twists and hidden secrets.\",\n",
    "    \"News\": \"This program covers current events and breaking news from around the world.\",\n",
    "    \"Reality-TV\": \"This show follows real people and their lives, providing entertainment and drama.\",\n",
    "    \"Romance\": \"A heartwarming romantic story unfolds in this film, full of love and emotions.\",\n",
    "    \"Sci-Fi\": \"This movie explores futuristic worlds, advanced technology, and space travel.\",\n",
    "    \"Short\": \"This is a short film that tells a compelling story in a brief runtime.\",\n",
    "    \"Sport\": \"This film is centered around sports, athletes, and competitive events.\",\n",
    "    \"Talk-Show\": \"This show features discussions, interviews, and engaging conversations.\",\n",
    "    \"Thriller\": \"This movie is filled with suspense, unexpected twists, and tension.\",\n",
    "    \"War\": \"This film portrays intense battles and the impact of war on people.\",\n",
    "    \"Western\": \"This movie is set in the Old West, featuring cowboys, duels, and frontier life.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_negatives = {\n",
    "    \"Action\": [\"Adventure\", \"Thriller\"],\n",
    "    \"Adult\": [\"Drama\", \"Romance\"],\n",
    "    \"Adventure\": [\"Fantasy\", \"Action\"],\n",
    "    \"Animation\": [\"Family\", \"Fantasy\"],\n",
    "    \"Biography\": [\"History\", \"Drama\"],\n",
    "    \"Comedy\": [\"Family\", \"Musical\"],\n",
    "    \"Crime\": [\"Thriller\", \"Drama\"],\n",
    "    \"Documentary\": [\"History\", \"News\"],\n",
    "    \"Drama\": [\"Romance\", \"Biography\"],\n",
    "    \"Family\": [\"Animation\", \"Comedy\"],\n",
    "    \"Fantasy\": [\"Sci-Fi\", \"Adventure\"],\n",
    "    \"Film-Noir\": [\"Mystery\", \"Thriller\"],\n",
    "    \"Game-Show\": [\"Reality-TV\", \"Talk-Show\"],\n",
    "    \"History\": [\"Biography\", \"Documentary\"],\n",
    "    \"Horror\": [\"Thriller\", \"Mystery\"],\n",
    "    \"Music\": [\"Musical\", \"Drama\"],\n",
    "    \"Musical\": [\"Music\", \"Comedy\"],\n",
    "    \"Mystery\": [\"Thriller\", \"Crime\"],\n",
    "    \"News\": [\"Documentary\", \"Talk-Show\"],\n",
    "    \"Reality-TV\": [\"Game-Show\", \"Talk-Show\"],\n",
    "    \"Romance\": [\"Drama\", \"Comedy\"],\n",
    "    \"Sci-Fi\": [\"Fantasy\", \"Action\"],\n",
    "    \"Short\": [\"Documentary\", \"Animation\"],\n",
    "    \"Sport\": [\"Drama\", \"Action\"],\n",
    "    \"Talk-Show\": [\"Reality-TV\", \"News\"],\n",
    "    \"Thriller\": [\"Horror\", \"Mystery\"],\n",
    "    \"War\": [\"History\", \"Drama\"],\n",
    "    \"Western\": [\"Adventure\", \"Action\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Three men hammer on an anvil and pass a bottle...</td>\n",
       "      <td>[Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Lost 1892 French short animated film directed ...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Lost short film consisting of 300 painted imag...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "      <td>[Animation, Comedy, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Performing on what looks like a small wooden s...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>Frog and Toad Are Friends</td>\n",
       "      <td>Claymation version of Arnold Lobel's story of ...</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>From Ardoyne to the Áras: Inside the McAleese ...</td>\n",
       "      <td>Documentary on the private and public life of ...</td>\n",
       "      <td>[Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>Frontstadt</td>\n",
       "      <td>A young filmmaker tries to gain a very persona...</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>Possible Changes</td>\n",
       "      <td>Two friends, Moon-ho and Jong-kyu, in their mi...</td>\n",
       "      <td>[Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>Full Grown Men</td>\n",
       "      <td>A man stuck in the reveries of his youth track...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0                                        Blacksmith Scene   \n",
       "1                                             Un bon bock   \n",
       "2                                  Le clown et ses chiens   \n",
       "3                                            Poor Pierrot   \n",
       "4                                              Carmencita   \n",
       "...                                                   ...   \n",
       "207356                          Frog and Toad Are Friends   \n",
       "207357  From Ardoyne to the Áras: Inside the McAleese ...   \n",
       "207358                                         Frontstadt   \n",
       "207359                                   Possible Changes   \n",
       "207360                                     Full Grown Men   \n",
       "\n",
       "                                                     desc  \\\n",
       "0       Three men hammer on an anvil and pass a bottle...   \n",
       "1       Lost 1892 French short animated film directed ...   \n",
       "2       Lost short film consisting of 300 painted imag...   \n",
       "3       One night, Arlequin come to see his lover Colo...   \n",
       "4       Performing on what looks like a small wooden s...   \n",
       "...                                                   ...   \n",
       "207356  Claymation version of Arnold Lobel's story of ...   \n",
       "207357  Documentary on the private and public life of ...   \n",
       "207358  A young filmmaker tries to gain a very persona...   \n",
       "207359  Two friends, Moon-ho and Jong-kyu, in their mi...   \n",
       "207360  A man stuck in the reveries of his youth track...   \n",
       "\n",
       "                          genre_list  \n",
       "0                            [Short]  \n",
       "1                 [Animation, Short]  \n",
       "2                 [Animation, Short]  \n",
       "3       [Animation, Comedy, Romance]  \n",
       "4               [Documentary, Short]  \n",
       "...                              ...  \n",
       "207356   [Animation, Comedy, Family]  \n",
       "207357                 [Documentary]  \n",
       "207358                       [Drama]  \n",
       "207359                       [Drama]  \n",
       "207360               [Comedy, Drama]  \n",
       "\n",
       "[207361 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = df[['title', 'desc', 'genre_list']]\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_counts = Counter(genre for genres in model_df[\"genre_list\"] for genre in genres)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "genre_count_df = pd.DataFrame(genre_counts.items(), columns=[\"Genre\", \"Count\"]).sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Drama</td>\n",
       "      <td>90068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>62317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Short</td>\n",
       "      <td>43939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romance</td>\n",
       "      <td>21667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>19763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Crime</td>\n",
       "      <td>19038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Action</td>\n",
       "      <td>18591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>14007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Family</td>\n",
       "      <td>12849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animation</td>\n",
       "      <td>12148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>10188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Horror</td>\n",
       "      <td>8093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Western</td>\n",
       "      <td>7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Music</td>\n",
       "      <td>6042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>War</td>\n",
       "      <td>5071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Musical</td>\n",
       "      <td>5041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Adult</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>History</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Biography</td>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sport</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Game-Show</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>News</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre  Count\n",
       "7         Drama  90068\n",
       "2        Comedy  62317\n",
       "0         Short  43939\n",
       "3       Romance  21667\n",
       "4   Documentary  19763\n",
       "12        Crime  19038\n",
       "17       Action  18591\n",
       "16    Adventure  14007\n",
       "15       Family  12849\n",
       "1     Animation  12148\n",
       "21     Thriller  10188\n",
       "8        Horror   8093\n",
       "13      Western   7813\n",
       "19      Mystery   6964\n",
       "9       Fantasy   6633\n",
       "11        Music   6042\n",
       "14          War   5071\n",
       "22      Musical   5041\n",
       "20       Sci-Fi   4666\n",
       "27        Adult   4470\n",
       "18      History   4335\n",
       "10    Biography   3662\n",
       "5         Sport   2585\n",
       "25    Game-Show    920\n",
       "23    Film-Noir    868\n",
       "24    Talk-Show    630\n",
       "6          News    611\n",
       "26   Reality-TV    451"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1064036/555546763.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"has_rare\"] = df[\"genre_list\"].apply(lambda x: any(g in rare_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
      "/tmp/ipykernel_1064036/555546763.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def final_balanced_under_sample(df, genre_counts):\n",
    "    \"\"\"\n",
    "    - 희귀 장르는 보호\n",
    "    - 빈도 높은 장르 (Drama, Comedy, Short) 강력 언더샘플링\n",
    "    - 특정 개수 기준으로 확실하게 줄이기\n",
    "    \"\"\"\n",
    "    sampled_df = pd.DataFrame()  # 최종 샘플링된 데이터 저장\n",
    "    processed_titles = set()  # 중복 방지를 위한 영화 제목 저장\n",
    "\n",
    "    # ✅ 희귀 장르 기준 (5000개 이하)\n",
    "    rare_genres = set([genre for genre, count in genre_counts.items() if count <= 5000])\n",
    "\n",
    "    # ✅ 빈도 높은 장르 기준 (15000개 이상)\n",
    "    high_freq_genres = set([genre for genre, count in genre_counts.items() if count >= 15000])\n",
    "\n",
    "    # 🎯 1. 희귀 장르 포함된 영화는 무조건 유지\n",
    "    df[\"has_rare\"] = df[\"genre_list\"].apply(lambda x: any(g in rare_genres for g in x))\n",
    "    rare_movies = df[df[\"has_rare\"]]\n",
    "\n",
    "    # 🎯 2. 희귀 장르가 없는 영화만 따로 분리\n",
    "    non_rare_movies = df[~df[\"has_rare\"]]\n",
    "\n",
    "    # 🎯 3. 빈도 높은 장르 포함된 영화 언더샘플링\n",
    "    high_freq_movies = pd.DataFrame()\n",
    "\n",
    "    for genre in high_freq_genres:\n",
    "        genre_data = non_rare_movies[non_rare_movies[\"genre_list\"].apply(lambda x: genre in x)]\n",
    "\n",
    "        # 🚨 완전 단독 장르는 삭제\n",
    "        genre_data[\"only_high_freq\"] = genre_data[\"genre_list\"].apply(lambda x: all(g in high_freq_genres for g in x))\n",
    "        only_high_freq_data = genre_data[genre_data[\"only_high_freq\"]]\n",
    "        mixed_genre_data = genre_data[~genre_data[\"only_high_freq\"]]\n",
    "\n",
    "        # 🎯 4. 단독으로 존재하는 빈도 높은 장르는 거의 삭제 (90% 이상 줄이기)\n",
    "        max_keep = min(len(only_high_freq_data) // 10, 1000)  # 최대 1000개만 유지\n",
    "        sampled_only_high_freq = only_high_freq_data.sample(max_keep, random_state=42) if len(only_high_freq_data) > max_keep else only_high_freq_data\n",
    "\n",
    "        # 🎯 5. 혼합된 장르는 조금만 줄이기\n",
    "        max_mixed_keep = min(len(mixed_genre_data) // 2, 5000)  # 최대 5000개 유지\n",
    "        sampled_mixed = mixed_genre_data.sample(max_mixed_keep, random_state=42) if len(mixed_genre_data) > max_mixed_keep else mixed_genre_data\n",
    "\n",
    "        high_freq_movies = pd.concat([high_freq_movies, sampled_only_high_freq, sampled_mixed])\n",
    "\n",
    "    # 🎯 6. 희귀 장르 포함된 영화 + 언더샘플링한 영화 결합\n",
    "    final_sampled_df = pd.concat([rare_movies, high_freq_movies])\n",
    "\n",
    "    return final_sampled_df.sample(frac=1, random_state=42).drop(columns=[\"has_rare\", \"only_high_freq\"])  # 최종 데이터 섞기\n",
    "\n",
    "\n",
    "# 🚀 언더샘플링 수행 (희귀 장르 보호 적용)\n",
    "undersampled_df = final_balanced_under_sample(model_df, Counter(genre for genres in model_df[\"genre_list\"] for genre in genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132153           [History, Short, War]\n",
       "161722                 [Comedy, Sport]\n",
       "63680          [Crime, Drama, History]\n",
       "88499         [Biography, Documentary]\n",
       "13342     [Action, Adventure, Romance]\n",
       "                      ...             \n",
       "191867    [Documentary, Drama, Family]\n",
       "64035       [Action, Musical, Romance]\n",
       "29549         [Comedy, Music, Romance]\n",
       "24349      [Biography, Drama, Musical]\n",
       "145095                         [Adult]\n",
       "Name: genre_list, Length: 55064, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_df['genre_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49559"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(undersampled_df[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genre_counts = Counter(genre for genres in undersampled_df[\"genre_list\"] for genre in genres)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "undersampled_genre_count_df = pd.DataFrame(genre_counts.items(), columns=[\"Genre\", \"Count\"]).sort_values(by=\"Count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drama</td>\n",
       "      <td>20785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>13994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short</td>\n",
       "      <td>9797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Action</td>\n",
       "      <td>9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crime</td>\n",
       "      <td>7981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>6764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Romance</td>\n",
       "      <td>6563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>5137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animation</td>\n",
       "      <td>5052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>4666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adult</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>History</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Family</td>\n",
       "      <td>4132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>4102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Biography</td>\n",
       "      <td>3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>3202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Horror</td>\n",
       "      <td>2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Music</td>\n",
       "      <td>2662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sport</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>War</td>\n",
       "      <td>2427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Musical</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Western</td>\n",
       "      <td>2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Game-Show</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Film-Noir</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Talk-Show</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>News</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Reality-TV</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Genre  Count\n",
       "6         Drama  20785\n",
       "3        Comedy  13994\n",
       "1         Short   9797\n",
       "9        Action   9129\n",
       "5         Crime   7981\n",
       "10    Adventure   6764\n",
       "11      Romance   6563\n",
       "8   Documentary   5137\n",
       "14    Animation   5052\n",
       "21       Sci-Fi   4666\n",
       "16        Adult   4470\n",
       "0       History   4335\n",
       "13       Family   4132\n",
       "18     Thriller   4102\n",
       "7     Biography   3662\n",
       "20      Mystery   3202\n",
       "23       Horror   2869\n",
       "17        Music   2662\n",
       "4         Sport   2585\n",
       "15      Fantasy   2517\n",
       "2           War   2427\n",
       "12      Musical   2153\n",
       "22      Western   2090\n",
       "26    Game-Show    920\n",
       "19    Film-Noir    868\n",
       "25    Talk-Show    630\n",
       "27         News    611\n",
       "24   Reality-TV    451"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_genre_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132153</th>\n",
       "      <td>Captain Molly, or the Battle of Monmouth</td>\n",
       "      <td>The country writhing under the yoke of British...</td>\n",
       "      <td>[History, Short, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161722</th>\n",
       "      <td>Mike Bassett: England Manager</td>\n",
       "      <td>Manager suffers heart attack. Unqualified repl...</td>\n",
       "      <td>[Comedy, Sport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63680</th>\n",
       "      <td>Angels of Iron</td>\n",
       "      <td>BERLIN, 1948. During the few days of the block...</td>\n",
       "      <td>[Crime, Drama, History]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88499</th>\n",
       "      <td>Family Values: An American Tragedy</td>\n",
       "      <td>Family Values: An American Tragedy tells the s...</td>\n",
       "      <td>[Biography, Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>A Regular Scout</td>\n",
       "      <td>Fred Blake sets out to avenge his mother who d...</td>\n",
       "      <td>[Action, Adventure, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191867</th>\n",
       "      <td>Silent Crisis: Diabetes Among Us</td>\n",
       "      <td>A one-hour documentary for the Discovery Healt...</td>\n",
       "      <td>[Documentary, Drama, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64035</th>\n",
       "      <td>Naseeb</td>\n",
       "      <td>A lottery ticket changes the lives of four fri...</td>\n",
       "      <td>[Action, Musical, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29549</th>\n",
       "      <td>Cinderella Jones</td>\n",
       "      <td>Judy Jones, sings with a band and also works a...</td>\n",
       "      <td>[Comedy, Music, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>The Story of Vernon and Irene Castle</td>\n",
       "      <td>The story of the dancing team who taught the w...</td>\n",
       "      <td>[Biography, Drama, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145095</th>\n",
       "      <td>The Backroom</td>\n",
       "      <td>Master Ken presides over San Francisco's infam...</td>\n",
       "      <td>[Adult]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "132153  Captain Molly, or the Battle of Monmouth   \n",
       "161722             Mike Bassett: England Manager   \n",
       "63680                             Angels of Iron   \n",
       "88499         Family Values: An American Tragedy   \n",
       "13342                            A Regular Scout   \n",
       "...                                          ...   \n",
       "191867          Silent Crisis: Diabetes Among Us   \n",
       "64035                                     Naseeb   \n",
       "29549                           Cinderella Jones   \n",
       "24349       The Story of Vernon and Irene Castle   \n",
       "145095                              The Backroom   \n",
       "\n",
       "                                                     desc  \\\n",
       "132153  The country writhing under the yoke of British...   \n",
       "161722  Manager suffers heart attack. Unqualified repl...   \n",
       "63680   BERLIN, 1948. During the few days of the block...   \n",
       "88499   Family Values: An American Tragedy tells the s...   \n",
       "13342   Fred Blake sets out to avenge his mother who d...   \n",
       "...                                                   ...   \n",
       "191867  A one-hour documentary for the Discovery Healt...   \n",
       "64035   A lottery ticket changes the lives of four fri...   \n",
       "29549   Judy Jones, sings with a band and also works a...   \n",
       "24349   The story of the dancing team who taught the w...   \n",
       "145095  Master Ken presides over San Francisco's infam...   \n",
       "\n",
       "                          genre_list  \n",
       "132153         [History, Short, War]  \n",
       "161722               [Comedy, Sport]  \n",
       "63680        [Crime, Drama, History]  \n",
       "88499       [Biography, Documentary]  \n",
       "13342   [Action, Adventure, Romance]  \n",
       "...                              ...  \n",
       "191867  [Documentary, Drama, Family]  \n",
       "64035     [Action, Musical, Romance]  \n",
       "29549       [Comedy, Music, Romance]  \n",
       "24349    [Biography, Drama, Musical]  \n",
       "145095                       [Adult]  \n",
       "\n",
       "[55064 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# 모델 로드 (8-bit 적용)\n",
    "MODEL_NAME = \"unsloth/phi-4-unsloth-bnb-4bit\"\n",
    "load_in_4bit = True\n",
    "max_seq_length = 1024\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = MODEL_NAME,\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     load_in_4bit = load_in_4bit,\n",
    "#     # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.2.15 patched 40 layers with 40 QKV layers, 40 O layers and 0 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 21,299,200 || all params: 14,680,806,400 || trainable%: 0.1451\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], # self-attention 레이어\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.print_trainable_parameters()  # 학습 가능한 파라미터만 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"🚨 Warning: NaN detected in {name} parameter!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 모든 LoRA 파라미터를 모델의 dtype과 동일하게 변환\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" in name:  # 🔥 LoRA 파라미터만 변환\n",
    "        param.data = param.data.to(model.dtype)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight torch.Size([5120, 16])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight torch.Size([1280, 16])\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight torch.Size([16, 5120])\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight torch.Size([5120, 16])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"lora\" in name:\n",
    "        print(name, param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters: 21299200\n"
     ]
    }
   ],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Trainable Parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_filtered_negative_samples(genre_list, all_genres, num_neg_samples=3):\n",
    "    \n",
    "    negative_candidates = list(set(all_genres) - set(genre_list))\n",
    "\n",
    "    hard_neg_candidates = []\n",
    "    for genre in genre_list:\n",
    "        if genre in hard_negatives:\n",
    "            hard_neg_candidates.extend(hard_negatives[genre])\n",
    "\n",
    "    # Hard Negative 후보 중에서 실제 Negative 후보와 겹치는 것만 선택\n",
    "    hard_neg_candidates = list(set(hard_neg_candidates) & set(negative_candidates))\n",
    "\n",
    "    # 최종 Negative 샘플링 (Hard Negative + 추가 Negative)\n",
    "    if len(hard_neg_candidates) < num_neg_samples:\n",
    "        # Hard Negative가 부족하면 일반 Negative에서 추가\n",
    "        additional_negatives = list(set(negative_candidates) - set(hard_neg_candidates))\n",
    "        sampled_additional_negatives = random.sample(additional_negatives, num_neg_samples - len(hard_neg_candidates))\n",
    "        final_neg_samples = hard_neg_candidates + sampled_additional_negatives\n",
    "    else:\n",
    "        # Hard Negative가 충분하면 거기서만 샘플링\n",
    "        final_neg_samples = random.sample(hard_neg_candidates, num_neg_samples)\n",
    "\n",
    "    # 장르 설명 텍스트 변환\n",
    "    neg_texts = [label_descriptions[neg] for neg in final_neg_samples]\n",
    "\n",
    "    return neg_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>has_rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Three men hammer on an anvil and pass a bottle...</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Lost 1892 French short animated film directed ...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Lost short film consisting of 300 painted imag...</td>\n",
       "      <td>[Animation, Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poor Pierrot</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "      <td>[Animation, Comedy, Romance]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Performing on what looks like a small wooden s...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207356</th>\n",
       "      <td>Frog and Toad Are Friends</td>\n",
       "      <td>Claymation version of Arnold Lobel's story of ...</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207357</th>\n",
       "      <td>From Ardoyne to the Áras: Inside the McAleese ...</td>\n",
       "      <td>Documentary on the private and public life of ...</td>\n",
       "      <td>[Documentary]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207358</th>\n",
       "      <td>Frontstadt</td>\n",
       "      <td>A young filmmaker tries to gain a very persona...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207359</th>\n",
       "      <td>Possible Changes</td>\n",
       "      <td>Two friends, Moon-ho and Jong-kyu, in their mi...</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207360</th>\n",
       "      <td>Full Grown Men</td>\n",
       "      <td>A man stuck in the reveries of his youth track...</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207361 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0                                        Blacksmith Scene   \n",
       "1                                             Un bon bock   \n",
       "2                                  Le clown et ses chiens   \n",
       "3                                            Poor Pierrot   \n",
       "4                                              Carmencita   \n",
       "...                                                   ...   \n",
       "207356                          Frog and Toad Are Friends   \n",
       "207357  From Ardoyne to the Áras: Inside the McAleese ...   \n",
       "207358                                         Frontstadt   \n",
       "207359                                   Possible Changes   \n",
       "207360                                     Full Grown Men   \n",
       "\n",
       "                                                     desc  \\\n",
       "0       Three men hammer on an anvil and pass a bottle...   \n",
       "1       Lost 1892 French short animated film directed ...   \n",
       "2       Lost short film consisting of 300 painted imag...   \n",
       "3       One night, Arlequin come to see his lover Colo...   \n",
       "4       Performing on what looks like a small wooden s...   \n",
       "...                                                   ...   \n",
       "207356  Claymation version of Arnold Lobel's story of ...   \n",
       "207357  Documentary on the private and public life of ...   \n",
       "207358  A young filmmaker tries to gain a very persona...   \n",
       "207359  Two friends, Moon-ho and Jong-kyu, in their mi...   \n",
       "207360  A man stuck in the reveries of his youth track...   \n",
       "\n",
       "                          genre_list  has_rare  \n",
       "0                            [Short]     False  \n",
       "1                 [Animation, Short]     False  \n",
       "2                 [Animation, Short]     False  \n",
       "3       [Animation, Comedy, Romance]     False  \n",
       "4               [Documentary, Short]     False  \n",
       "...                              ...       ...  \n",
       "207356   [Animation, Comedy, Family]     False  \n",
       "207357                 [Documentary]     False  \n",
       "207358                       [Drama]     False  \n",
       "207359                       [Drama]     False  \n",
       "207360               [Comedy, Drama]     False  \n",
       "\n",
       "[207361 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ContrastiveDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, all_genres=None, max_length=128, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.all_genres = all_genres\n",
    "        self.max_length = max_length\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        title = row[\"title\"]\n",
    "        description = row[\"desc\"]\n",
    "        genre_list = row[\"genre_list\"]\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "\n",
    "            neg_texts = get_filtered_negative_samples(genre_list, all_genres)\n",
    "\n",
    "            story_prompt = f\"Movie Title: {title}, Story: {description}\"\n",
    "            label_prompt_pos = [\"Label: \" + label_descriptions[pos] for pos in genre_list]\n",
    "            label_prompt_neg = [\"Label: \" + neg for neg in neg_texts]  # 여러 개의 Negative 샘플\n",
    "\n",
    "            text_enc = self.tokenizer(story_prompt, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "            pos_enc = self.tokenizer(label_prompt_pos, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "            neg_enc = self.tokenizer(label_prompt_neg, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "            return {\n",
    "                \"text_input_ids\": text_enc[\"input_ids\"].squeeze(0),\n",
    "                \"text_attention_mask\": text_enc[\"attention_mask\"].squeeze(0),\n",
    "                \"positive_input_ids\": pos_enc[\"input_ids\"],\n",
    "                \"positive_attention_mask\": pos_enc[\"attention_mask\"],\n",
    "                \"negative_input_ids\": neg_enc[\"input_ids\"],\n",
    "                \"negative_attention_mask\": neg_enc[\"attention_mask\"]\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            return {\n",
    "                \"title\": title,\n",
    "                \"description\": description,\n",
    "                \"answer\": genre_list\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(undersampled_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = ContrastiveDataset(train_df, tokenizer, all_genres=all_genres)\n",
    "val_dataset = ContrastiveDataset(val_df, tokenizer, all_genres=all_genres)\n",
    "test_dataset = ContrastiveDataset(val_df, tokenizer, mode=\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    \"\"\"배치 내 `positive_input_ids`의 크기를 맞추는 함수\"\"\"\n",
    "\n",
    "    text_input_ids = torch.stack([b[\"text_input_ids\"] for b in batch])\n",
    "    text_attention_mask = torch.stack([b[\"text_attention_mask\"] for b in batch])\n",
    "\n",
    "    # 🔹 Positive 샘플 패딩 적용 (가장 큰 `num_positives` 기준)\n",
    "    max_pos_samples = max([b[\"positive_input_ids\"].shape[0] for b in batch])  # 배치 내 가장 긴 긍정 샘플 개수 찾기\n",
    "    pos_input_ids = [torch.cat([b[\"positive_input_ids\"], torch.zeros(max_pos_samples - b[\"positive_input_ids\"].shape[0], b[\"positive_input_ids\"].shape[1])]) if b[\"positive_input_ids\"].shape[0] < max_pos_samples else b[\"positive_input_ids\"] for b in batch]\n",
    "    pos_attention_mask = [torch.cat([b[\"positive_attention_mask\"], torch.zeros(max_pos_samples - b[\"positive_attention_mask\"].shape[0], b[\"positive_attention_mask\"].shape[1])]) if b[\"positive_attention_mask\"].shape[0] < max_pos_samples else b[\"positive_attention_mask\"] for b in batch]\n",
    "\n",
    "    pos_input_ids = torch.stack(pos_input_ids)\n",
    "    pos_attention_mask = torch.stack(pos_attention_mask)\n",
    "\n",
    "    # 🔹 Negative 샘플 (3개로 고정)\n",
    "    neg_input_ids = torch.stack([b[\"negative_input_ids\"] for b in batch])\n",
    "    neg_attention_mask = torch.stack([b[\"negative_attention_mask\"] for b in batch])\n",
    "\n",
    "    return {\n",
    "        \"text_input_ids\": text_input_ids,\n",
    "        \"text_attention_mask\": text_attention_mask,\n",
    "        \"positive_input_ids\": pos_input_ids.to(torch.long),\n",
    "        \"positive_attention_mask\": pos_attention_mask,\n",
    "        \"negative_input_ids\": neg_input_ids.to(torch.long),\n",
    "        \"negative_attention_mask\": neg_attention_mask\n",
    "    }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Test 데이터에서 배치 크기 불일치 문제 해결\n",
    "    - `title`, `description`, `answer`를 리스트로 유지하여 DataLoader가 처리 가능하도록 함\n",
    "    \"\"\"\n",
    "    titles = [item[\"title\"] for item in batch]\n",
    "    descriptions = [item[\"description\"] for item in batch]\n",
    "    answers = [item[\"answer\"] for item in batch]  # 리스트 형태 유지\n",
    "\n",
    "    return {\n",
    "        \"title\": titles,\n",
    "        \"description\": descriptions,\n",
    "        \"answer\": answers\n",
    "    }\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=train_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=train_collate_fn)  # 검증 데이터는 shuffle X\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m      2\u001b[0m dtype\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "dtype = model.dtype\n",
    "dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def info_nce_loss(query, positives, negatives, temperature=0.1, eps=1e-12):\n",
    "    \"\"\"\n",
    "    - Contrastive InfoNCE loss with multiple positive & negative samples\n",
    "    - Handles NaN/Inf issues using `clamp()` and `nan_to_num()`\n",
    "    \"\"\"\n",
    "    # 🚀 1. Normalize embeddings\n",
    "    query = F.normalize(query, p=2, dim=-1, eps=eps)\n",
    "    positives = F.normalize(positives, p=2, dim=-1, eps=eps)\n",
    "    negatives = F.normalize(negatives, p=2, dim=-1, eps=eps)\n",
    "\n",
    "    # 🚀 2. Compute similarity scores (`clamp()` 범위 수정)\n",
    "    pos_sim = torch.exp(torch.clamp(torch.matmul(query.unsqueeze(1), positives.permute(0, 2, 1)).squeeze(1) / temperature, -20, 20))\n",
    "    neg_sim = torch.exp(torch.clamp(torch.matmul(query.unsqueeze(1), negatives.permute(0, 2, 1)).squeeze(1) / temperature, -20, 20))\n",
    "\n",
    "    # 🚀 3. Compute denominator\n",
    "    pos_sim_sum = torch.sum(pos_sim, dim=-1)  # (batch_size)\n",
    "    neg_sim_sum = torch.sum(neg_sim, dim=-1)  # (batch_size)\n",
    "    denominator = pos_sim_sum + neg_sim_sum + eps  # 🚀 eps 줄임\n",
    "\n",
    "    # 🚀 4. Compute loss\n",
    "    loss = -torch.log(pos_sim_sum / denominator)\n",
    "\n",
    "    # 🚀 5. Handle NaN values\n",
    "    loss = torch.nan_to_num(loss, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "\n",
    "    # 🚨 Debugging print (최초 몇 개만 출력)\n",
    "    if torch.isnan(loss).any() or loss.mean().item() == 0:\n",
    "        print(\"🚨 Warning: Loss is NaN or 0!\")\n",
    "        print(f\"pos_sim: {pos_sim[:3]}\")\n",
    "        print(f\"neg_sim: {neg_sim[:3]}\")\n",
    "        print(f\"denominator: {denominator[:3]}\")\n",
    "        print(f\"loss: {loss[:3]}\")\n",
    "\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_group in optimizer.param_groups:\n",
    "#     param_group['params'] = [p.to(model.dtype) for p in param_group['params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n",
      "Optimizer Param dtype: torch.bfloat16, Model dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group['params']:\n",
    "        print(f\"Optimizer Param dtype: {param.dtype}, Model dtype: {model.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.36.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.37.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.38.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.q_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.k_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.v_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_A.default.weight: torch.bfloat16, requires_grad=True\n",
      "base_model.model.model.layers.39.self_attn.o_proj.lora_B.default.weight: torch.bfloat16, requires_grad=True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.dtype}, requires_grad={param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 🚀 체크포인트 저장/불러오기 설정\n",
    "CHECKPOINT_PATH = \"model_checkpoint.pth\"\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, avg_train_loss, avg_val_loss, best_val_loss):\n",
    "    \"\"\" 학습 중간에 체크포인트 저장 \"\"\"\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"best_val_loss\": best_val_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "    print(f\"✅ Checkpoint saved at epoch {epoch+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer):\n",
    "    \"\"\" 체크포인트 불러오기 (있을 경우) \"\"\"\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1  # 다음 에포크부터 학습 시작\n",
    "        best_val_loss = checkpoint[\"best_val_loss\"]\n",
    "        print(f\"🔄 Resuming from checkpoint at epoch {start_epoch}\")\n",
    "        return start_epoch, best_val_loss\n",
    "    return 0, float(\"inf\")  # 처음부터 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 검증(Validation) 함수 정의\n",
    "def validation_step(model, val_dataloader):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dataloader, desc=\"Validating\", leave=False):\n",
    "            query_emb = model(batch[\"text_input_ids\"], batch[\"text_attention_mask\"]).last_hidden_state[:, 0]\n",
    "\n",
    "            batch_size, num_positives, seq_len = batch[\"positive_input_ids\"].shape  \n",
    "            pos_input_ids = batch[\"positive_input_ids\"].reshape(batch_size * num_positives, seq_len)\n",
    "            pos_attention_mask = batch[\"positive_attention_mask\"].reshape(batch_size * num_positives, seq_len)\n",
    "\n",
    "            pos_output = model(input_ids=pos_input_ids, attention_mask=pos_attention_mask, output_hidden_states=True)\n",
    "            pos_emb = pos_output.hidden_states[-1][:, 0].reshape(batch_size, num_positives, -1)\n",
    "\n",
    "            batch_size, num_negatives, seq_len = batch[\"negative_input_ids\"].shape\n",
    "            neg_input_ids = batch[\"negative_input_ids\"].reshape(batch_size * num_negatives, seq_len)\n",
    "            neg_attention_mask = batch[\"negative_attention_mask\"].reshape(batch_size * num_negatives, seq_len)\n",
    "\n",
    "            neg_output = model(input_ids=neg_input_ids, attention_mask=neg_attention_mask, output_hidden_states=True)\n",
    "            neg_emb = neg_output.hidden_states[-1][:, 0].reshape(batch_size, num_negatives, -1)\n",
    "\n",
    "            # InfoNCE 손실 계산\n",
    "            loss = info_nce_loss(query_emb, pos_emb, neg_emb)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "    wandb.log({\"Val Loss\": avg_val_loss})\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if torch.isnan(param).any():\n",
    "        print(f\"🚨 Warning: NaN detected in {name} parameter!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11013"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/11013 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/11013 [00:01<?, ?it/s]\n",
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1891: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  start = re.search('logger\\.info\\([\\\"\\'].+?Running training', inner_training_loop).span(0)[0]\n",
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1894: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  spaces = re.search('\\n([\\s\\t]{1,})', original_debug).group(0)[1:]\n",
      "/home/jiyoon/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1895: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  front_spaces = re.match('([\\s\\t]{1,})', inner_training_loop).group(0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 🔥 Query 임베딩 추출\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m query_emb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_input_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_attention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhidden_states[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 🔥 Positive Sample 임베딩\u001b[39;00m\n\u001b[1;32m     33\u001b[0m batch_size, num_positives, seq_len \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape  \n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1216\u001b[0m, in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_dynamo\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mPeftModelForCausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1215\u001b[0m ):\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:1061\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_has_no_labels \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:853\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m offloaded_gradient_checkpointing:\n\u001b[0;32m--> 853\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mUnsloth_Offloaded_Gradient_Checkpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m gradient_checkpointing:\n\u001b[1;32m    867\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_custom_forward\u001b[39m(module):\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/amp/autocast_mode.py:503\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n\u001b[0;32m--> 503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth_zoo/gradient_checkpointing.py:147\u001b[0m, in \u001b[0;36mUnsloth_Offloaded_Gradient_Checkpointer.forward\u001b[0;34m(ctx, forward_function, hidden_states, *args)\u001b[0m\n\u001b[1;32m    145\u001b[0m saved_hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, non_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 147\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(saved_hidden_states)\n\u001b[1;32m    149\u001b[0m ctx\u001b[38;5;241m.\u001b[39mforward_function \u001b[38;5;241m=\u001b[39m forward_function\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/unsloth/models/llama.py:548\u001b[0m, in \u001b[0;36mLlamaDecoderLayer_fast_forward\u001b[0;34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    547\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm, hidden_states)\n\u001b[0;32m--> 548\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    549\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:242\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 242\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/RecLLM/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected mat1 and mat2 to have the same dtype, but got: c10::BFloat16 != float"
     ]
    }
   ],
   "source": [
    "# 🚀 학습 루프 (체크포인트 기능 포함)\n",
    "num_epochs = 3\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# 🔄 체크포인트에서 불러오기 (이전 학습 재개)\n",
    "start_epoch, best_val_loss = load_checkpoint(model, optimizer)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for batch in train_bar:\n",
    "        for key, value in batch.items():\n",
    "            if torch.isnan(value).any():\n",
    "                print(f\"❌ NaN detected in batch[{key}]\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
    "\n",
    "        batch[\"text_input_ids\"] = batch[\"text_input_ids\"].to(device)\n",
    "        batch[\"text_attention_mask\"] = batch[\"text_attention_mask\"].to(device)\n",
    "        batch[\"positive_input_ids\"] = batch[\"positive_input_ids\"].to(device)\n",
    "        batch[\"positive_attention_mask\"] = batch[\"positive_attention_mask\"].to(device)\n",
    "        batch[\"negative_input_ids\"] = batch[\"negative_input_ids\"].to(device)\n",
    "        batch[\"negative_attention_mask\"] = batch[\"negative_attention_mask\"].to(device)\n",
    "\n",
    "        # 🔥 Query 임베딩 추출\n",
    "        query_emb = model(batch[\"text_input_ids\"], batch[\"text_attention_mask\"], output_hidden_states=True).hidden_states[-1][:, 0]\n",
    "\n",
    "        # 🔥 Positive Sample 임베딩\n",
    "        batch_size, num_positives, seq_len = batch[\"positive_input_ids\"].shape  \n",
    "        pos_input_ids = batch[\"positive_input_ids\"].view(batch_size * num_positives, seq_len)\n",
    "        pos_attention_mask = batch[\"positive_attention_mask\"].view(batch_size * num_positives, seq_len)\n",
    "        pos_output = model(input_ids=pos_input_ids, attention_mask=pos_attention_mask, output_hidden_states=True)\n",
    "        pos_emb = pos_output.hidden_states[-1][:, 0].view(batch_size, num_positives, -1)  # 원래 배치 형태로 복구\n",
    "\n",
    "        # 🔥 Negative Sample 임베딩\n",
    "        batch_size, num_negatives, seq_len = batch[\"negative_input_ids\"].shape\n",
    "        neg_input_ids = batch[\"negative_input_ids\"].view(batch_size * num_negatives, seq_len)\n",
    "        neg_attention_mask = batch[\"negative_attention_mask\"].view(batch_size * num_negatives, seq_len)\n",
    "        neg_output = model(input_ids=neg_input_ids, attention_mask=neg_attention_mask, output_hidden_states=True)\n",
    "        neg_emb = neg_output.hidden_states[-1][:, 0].view(batch_size, num_negatives, -1)\n",
    "\n",
    "        # # ✅ 값이 너무 크거나 작아지는 것 방지\n",
    "        # query_emb = query_emb.clone().clamp(-1e6, 1e6)\n",
    "        # pos_emb = pos_emb.clone().clamp(-1e6, 1e6)\n",
    "        # neg_emb = neg_emb.clone().clamp(-1e6, 1e6)\n",
    "\n",
    "\n",
    "        # 🔥 InfoNCE 손실 계산\n",
    "        loss = info_nce_loss(query_emb, pos_emb, neg_emb)\n",
    "        if torch.isnan(loss).any():\n",
    "            print(\"❌ Loss contains NaN values!\")\n",
    "            exit()\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if torch.isnan(param).any():\n",
    "                print(f\"❌ NaN detected in model parameter: {name}\")\n",
    "\n",
    "\n",
    "        # 🚀 **GradScaler 제거 후 직접 backward() 적용**\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)]\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None and torch.isnan(param.grad).any():\n",
    "                print(f\"❌ NaN detected in gradients of {name}\")\n",
    "                exit()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    avg_val_loss = validation_step(model, val_dataloader)  # 🚀 Validation에도 AMP 적용 필요\n",
    "\n",
    "    wandb.log({\"Train Loss\": avg_train_loss, \"Val Loss\": avg_val_loss})\n",
    "    print(f\"✅ Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "    # 🚀 **베스트 모델 체크포인트 저장**\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        save_checkpoint(epoch, model, optimizer, avg_train_loss, avg_val_loss, best_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 🚀 저장할 디렉토리 설정\n",
    "save_directory = \"fine_tuned_phi4_lora\"\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "# ✅ LoRA Adapter 저장\n",
    "model.save_pretrained(save_directory)  # LoRA Adapter 저장\n",
    "tokenizer.save_pretrained(save_directory)  # 토크나이저 저장\n",
    "\n",
    "print(f\"✅ Model and LoRA adapter saved at {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.69s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 🔹 Hugging Face Text Generation Pipeline 설정\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"unsloth/phi-4-unsloth-bnb-4bit\",\n",
    "    model_kwargs={\"torch_dtype\": \"auto\"},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2754"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132153</th>\n",
       "      <td>Captain Molly, or the Battle of Monmouth</td>\n",
       "      <td>The country writhing under the yoke of British...</td>\n",
       "      <td>[History, Short, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161722</th>\n",
       "      <td>Mike Bassett: England Manager</td>\n",
       "      <td>Manager suffers heart attack. Unqualified repl...</td>\n",
       "      <td>[Comedy, Sport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63680</th>\n",
       "      <td>Angels of Iron</td>\n",
       "      <td>BERLIN, 1948. During the few days of the block...</td>\n",
       "      <td>[Crime, Drama, History]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88499</th>\n",
       "      <td>Family Values: An American Tragedy</td>\n",
       "      <td>Family Values: An American Tragedy tells the s...</td>\n",
       "      <td>[Biography, Documentary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13342</th>\n",
       "      <td>A Regular Scout</td>\n",
       "      <td>Fred Blake sets out to avenge his mother who d...</td>\n",
       "      <td>[Action, Adventure, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191867</th>\n",
       "      <td>Silent Crisis: Diabetes Among Us</td>\n",
       "      <td>A one-hour documentary for the Discovery Healt...</td>\n",
       "      <td>[Documentary, Drama, Family]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64035</th>\n",
       "      <td>Naseeb</td>\n",
       "      <td>A lottery ticket changes the lives of four fri...</td>\n",
       "      <td>[Action, Musical, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29549</th>\n",
       "      <td>Cinderella Jones</td>\n",
       "      <td>Judy Jones, sings with a band and also works a...</td>\n",
       "      <td>[Comedy, Music, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>The Story of Vernon and Irene Castle</td>\n",
       "      <td>The story of the dancing team who taught the w...</td>\n",
       "      <td>[Biography, Drama, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145095</th>\n",
       "      <td>The Backroom</td>\n",
       "      <td>Master Ken presides over San Francisco's infam...</td>\n",
       "      <td>[Adult]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "132153  Captain Molly, or the Battle of Monmouth   \n",
       "161722             Mike Bassett: England Manager   \n",
       "63680                             Angels of Iron   \n",
       "88499         Family Values: An American Tragedy   \n",
       "13342                            A Regular Scout   \n",
       "...                                          ...   \n",
       "191867          Silent Crisis: Diabetes Among Us   \n",
       "64035                                     Naseeb   \n",
       "29549                           Cinderella Jones   \n",
       "24349       The Story of Vernon and Irene Castle   \n",
       "145095                              The Backroom   \n",
       "\n",
       "                                                     desc  \\\n",
       "132153  The country writhing under the yoke of British...   \n",
       "161722  Manager suffers heart attack. Unqualified repl...   \n",
       "63680   BERLIN, 1948. During the few days of the block...   \n",
       "88499   Family Values: An American Tragedy tells the s...   \n",
       "13342   Fred Blake sets out to avenge his mother who d...   \n",
       "...                                                   ...   \n",
       "191867  A one-hour documentary for the Discovery Healt...   \n",
       "64035   A lottery ticket changes the lives of four fri...   \n",
       "29549   Judy Jones, sings with a band and also works a...   \n",
       "24349   The story of the dancing team who taught the w...   \n",
       "145095  Master Ken presides over San Francisco's infam...   \n",
       "\n",
       "                          genre_list  \n",
       "132153         [History, Short, War]  \n",
       "161722               [Comedy, Sport]  \n",
       "63680        [Crime, Drama, History]  \n",
       "88499       [Biography, Documentary]  \n",
       "13342   [Action, Adventure, Romance]  \n",
       "...                              ...  \n",
       "191867  [Documentary, Drama, Family]  \n",
       "64035     [Action, Musical, Romance]  \n",
       "29549       [Comedy, Music, Romance]  \n",
       "24349    [Biography, Drama, Musical]  \n",
       "145095                       [Adult]  \n",
       "\n",
       "[55064 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the maximum number of genres assigned to a single movie\n",
    "max_genres_per_movie = undersampled_df[\"genre_list\"].apply(len).max()\n",
    "\n",
    "# Display the result\n",
    "max_genres_per_movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_llm_generation(test_dataloader, all_genres, output_file=\"llm_predictions.txt\"):\n",
    "    \"\"\"\n",
    "    - `unsloth/phi-4-unsloth-bnb-4bit` 모델을 사용하여 장르를 예측하고 평가\n",
    "    - `.txt` 파일에 `[Prompt] [LLM Predictions] [Answer]` 형식으로 저장\n",
    "    - Precision, Recall, F1-score 계산 후 파일에 추가\n",
    "    \"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"LLM Movie Genre Prediction Results\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\\n\")\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v for k, v in batch.items()}  # 타이틀, 설명, 정답 포함\n",
    "\n",
    "        # 🚀 프롬프트 메시지 생성 (대화형 메시지 포맷 적용)\n",
    "        prompts = [\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": f\"You are an AI movie genre classifier. Your task is to assign the most appropriate genres to a movie. Follow these rules: 1. Choose ONLY from the given genres: {', '.join(all_genres)}. 2.Assign the most relevant genres (1, 2, or 3) based on fit. If a movie strongly fits only one genre, assign just one. If two genres are a good fit, assign two. 3. Output ONLY the predicted genres as a comma-separated list. 4. Do NOT repeat or copy the full genre list. 5. Do NOT add explanations or extra text.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Movie Title: {title}, Story: {desc}, Predicted Genres:\"}\n",
    "            ]\n",
    "            for title, desc in zip(batch[\"title\"], batch[\"description\"])\n",
    "        ]\n",
    "        \n",
    "\n",
    "        # 🚀 모델 예측 수행 (배치 단위로 처리)\n",
    "        outputs = [pipeline(prompt, max_new_tokens=15)[0][\"generated_text\"][-1] for prompt in prompts]\n",
    "\n",
    "        # 🚀 LLM이 생성한 장르 필터링 (올바른 장르만 포함)\n",
    "        filtered_preds = []\n",
    "        for pred in outputs:\n",
    "            pred_text = pred['content']\n",
    "            pred_lst = [genre.strip() for genre in pred_text.split(',')]\n",
    "            # pred_genres = [genre for genre in all_genres if genre in pred_lst]  # 정해진 장르 목록에 포함된 것만 선택\n",
    "            filtered_preds.append(pred_lst)\n",
    "\n",
    "        # 🚀 실제 정답 가져오기\n",
    "        actual_labels = batch[\"answer\"]\n",
    "\n",
    "        # 🚀 파일에 기록 (지정된 형식 적용)\n",
    "        with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            for prompt, pred, actual in zip(prompts, filtered_preds, actual_labels):\n",
    "                f.write(f\"[Prompt]\\n{prompt}\\n\\n\")\n",
    "                f.write(f\"[LLM Predictions]\\n{', '.join(pred)}\\n\\n\")\n",
    "                f.write(f\"[Answer]\\n{', '.join(actual)}\\n\")\n",
    "                f.write(\"-\" * 100 + \"\\n\\n\")\n",
    "\n",
    "        # 🚀 모델의 예측값을 리스트로 변환\n",
    "        pred_vectors = [[1 if genre in pred else 0 for genre in all_genres] for pred in filtered_preds]\n",
    "        label_vectors = [[1 if genre in actual else 0 for genre in all_genres] for actual in actual_labels]\n",
    "\n",
    "        all_preds.extend(pred_vectors)\n",
    "        all_labels.extend(label_vectors)\n",
    "\n",
    "    # 🚀 Precision, Recall, F1-score 계산\n",
    "    precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "    recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"LLM Generation - Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    # 🚀 평가 결과 파일에 저장\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\" + \"=\" * 100 + \"\\n\")\n",
    "        f.write(f\"Final Evaluation Metrics:\\n\")\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        f.write(f\"F1-score: {f1:.4f}\\n\")\n",
    "        f.write(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Generation - Precision: 0.5659, Recall: 0.6016, F1-score: 0.5488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5658517449133696, 0.6015991047924049, 0.5487915194729224)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_llm_generation(test_dataloader, all_genres)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecLLM",
   "language": "python",
   "name": "recllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
